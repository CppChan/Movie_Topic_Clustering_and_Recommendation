{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 1.0758548471157916\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "conf = org.apache.spark.SparkConf@3964116a\n",
       "sc = org.apache.spark.SparkContext@1cac74fd\n",
       "spark = org.apache.spark.sql.SparkSession@6a1ad95f\n",
       "train_raw = MapPartitionsRDD[4] at filter at <console>:43\n",
       "test_raw = MapPartitionsRDD[5] at filter at <console>:45\n",
       "train_header = user_...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "user_id,business_id,stars"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.SparkContext\n",
    "import org.apache.spark.SparkConf\n",
    "import org.apache.spark.rdd.RDD\n",
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.SparkContext._\n",
    "import org.apache.spark.mllib.recommendation.ALS\n",
    "import org.apache.spark.mllib.recommendation.MatrixFactorizationModel\n",
    "import org.apache.spark.mllib.recommendation.Rating  \n",
    "\n",
    "    val conf = new SparkConf().setAppName(\"response_count\").setMaster(\"local[2]\")\n",
    "    val sc = new SparkContext(conf)\n",
    "    val spark = SparkSession.builder.getOrCreate\n",
    "\n",
    "    var train_raw = sc.textFile(\"./Data/train_review.csv\")\n",
    "    var test_raw = sc.textFile(\"./Data/test_review.csv\")\n",
    "    val train_header = train_raw.first()\n",
    "    train_raw = train_raw.filter(row => row != train_header)\n",
    "    val test_header = test_raw.first()\n",
    "    test_raw = test_raw.filter(row => row != test_header)\n",
    "    val n = test_raw.count()\n",
    "\n",
    "    //convert user to user_id\n",
    "    var train_rating = train_raw.map(_.split(','))\n",
    "    var test_rating = test_raw.map(_.split(','))\n",
    "    var all_rating = train_rating.union(test_rating)\n",
    "    var user = all_rating.map(x=>(x(0),1)).reduceByKey((a, b) => a + b)\n",
    "    val user_encode = user.map(x=>x._1).zipWithUniqueId().collect().toMap\n",
    "    var train_rating_1 = train_rating.map(x=>(user_encode(x(0)).toInt,x(1),x(2)))\n",
    "\n",
    "//    var user_test = test_rating.map(x=>(x(0),1)).reduceByKey((a, b) => a + b)\n",
    "//    val user_encode_test = user_test.map(x=>x._1).zipWithUniqueId().collect().toMap\n",
    "    var test_rating_1 = test_rating.map(x=>(user_encode(x(0)).toInt,x(1),x(2)))\n",
    "\n",
    "\n",
    "\n",
    "    //conver product to product_id\n",
    "    var product = all_rating.map(x=>(x(1),1)).reduceByKey((a, b) => a + b)\n",
    "    val product_encode = product.map(x=>x._1).zipWithUniqueId().collect().toMap\n",
    "    var train_rating_2 = train_rating_1.map(x=>(x._1,product_encode(x._2).toInt,x._3.toDouble))\n",
    "//    train_rating_2.foreach(println)\n",
    "\n",
    "//    var product_test = test_rating.map(x=>(x(1),1)).reduceByKey((a, b) => a + b)\n",
    "//    val product_encode_test = product_test.map(x=>x._1).zipWithUniqueId().collect().toMap\n",
    "    var test_rating_2 = test_rating_1.map(x=>(x._1,product_encode(x._2).toInt,x._3.toDouble))\n",
    "//    test_rating_2.foreach(println)\n",
    "\n",
    "\n",
    "    //ALS\n",
    "    val ratings = train_rating_2.map(_ match { case (user, item, rate) =>\n",
    "      Rating(user.toInt, item.toInt, rate.toDouble)})\n",
    "    val test_ratings = test_rating_2.map(_ match { case (user, item, rate) =>\n",
    "      Rating(user.toInt, item.toInt, rate.toDouble)})\n",
    "    val rank = 20\n",
    "    val numIterations = 20\n",
    "    val model = ALS.train(ratings, rank, numIterations, 0.3)\n",
    "\n",
    "    // Evaluate the model on rating data\n",
    "    val test_Products = test_ratings.map { case Rating(user, product, rate) =>\n",
    "      (user, product)\n",
    "    }\n",
    "    val predictions =\n",
    "      model.predict(test_Products).map { case Rating(user, product, rate) =>\n",
    "        ((user, product), rate)\n",
    "      }\n",
    "    val ratesAndPreds = test_ratings.map { case Rating(user, product, rate) =>\n",
    "      ((user, product), rate)\n",
    "    }.join(predictions)\n",
    "    val SE = ratesAndPreds.map { case ((user, product), (r1, r2)) =>\n",
    "      val err = (r1 - r2)\n",
    "      err * err\n",
    "    }.sum()\n",
    "    val RMSE = math.sqrt(SE/n)\n",
    "    println(s\"RMSE = $RMSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((5205,25090),(3.0,3.205511950687981))"
     ]
    },
    {
     "data": {
      "text/plain": [
       "rate_first = ((5205,25090),(3.0,3.205511950687981))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "((5205,25090),(3.0,3.205511950687981))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val rate_first = ratesAndPreds.first()\n",
    "print(rate_first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20551195068798078"
     ]
    },
    {
     "data": {
      "text/plain": [
       "error = MapPartitionsRDD[432] at map at <console>:61\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[432] at map at <console>:61"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val error = ratesAndPreds.map { case((user, product), (r1, r2)) =>\n",
    "      math.abs(r1-r2)}\n",
    "print(error.first())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "error = MapPartitionsRDD[437] at map at <console>:61\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[437] at map at <console>:61"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    var error = ratesAndPreds.map { case((user, product), (r1, r2)) =>\n",
    "      math.abs(r1-r2)}\n",
    "      .map(err=>{\n",
    "      if (err.toFloat < 1 && err.toFloat >= 0){\n",
    "        0\n",
    "      }else if (err.toFloat >= 1 && err.toFloat < 2) {\n",
    "        1\n",
    "      }else if (err.toFloat >= 2 && err.toFloat < 3) {\n",
    "        2\n",
    "      }else if (err.toFloat >= 3 && err.toFloat < 4) {\n",
    "        3\n",
    "      }else if (err.toFloat >= 4 && err.toFloat < 5) {\n",
    "        4\n",
    "      }\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "level_err = ShuffledRDD[446] at reduceByKey at <console>:63\n",
       "level1 = 28009\n",
       "level2 = 13835\n",
       "level3 = 2339\n",
       "level4 = 241\n",
       "level5 = 35\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    var level_err = error.map(_->1).reduceByKey((a, b) => a + b)\n",
    "    var level1 = level_err.filter(_._1==0).first()._2\n",
    "    var level2 = level_err.filter(_._1==1).first()._2\n",
    "    var level3 = level_err.filter(_._1==2).first()._2\n",
    "    var level4 = level_err.filter(_._1==3).first()._2\n",
    "    var level5 = level_err.filter(_._1==4).first()._2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Syntax Error.\n",
       "Message: \n",
       "StackTrace: "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Task2 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark2.3.1 - Scala",
   "language": "scala",
   "name": "spark2.3.1_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
